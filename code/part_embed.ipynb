{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c749cea539fe4f69bbf2f42a0e8538dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b798810e9c664975ad7905cd02025d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6af6667035488399e0356a2084aff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298a3041d96d436eab676c370cc7ea50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a1ff89ef9a4106ad0e31a2789fea74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f821785cf4647538f847b0223e07aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "# Load the model\n",
    "model_name = \"roberta-large\"\n",
    "model = RobertaModel.from_pretrained(model_name)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = pd.read_csv('../Data/new_gpt2.csv')\n",
    "human = pd.read_csv('../Data/new_human.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        #embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # Mean pooling of token embeddings\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        embeddings = last_hidden_states[:,0,:]\n",
    "    return embeddings.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def min_max_normalize(embeddings):\n",
    "    # Find the minimum and maximum values in the embeddings\n",
    "    min_val = np.min(embeddings)\n",
    "    max_val = np.max(embeddings)\n",
    "    \n",
    "    # Normalize the embeddings to range [0, 255]\n",
    "    normalized_embeddings = 255 * (embeddings - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_embeddings.astype(np.uint8)  # Convert to uint8 for integer values between 0 and 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_embeddings(embeddings):\n",
    "    # Reshape the embeddings to 3D array\n",
    "    return embeddings.reshape(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt['embeddings'] = gpt['Generation'].apply(generate_bert_embeddings)\n",
    "gpt['normalized_embeddings'] = gpt['embeddings'].apply(min_max_normalize)\n",
    "gpt['reshaped_embeddings'] = gpt['normalized_embeddings'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [[235, 233, 235, 239, 241, 236, 236, 234, 239,...\n",
      "1       [[225, 227, 225, 234, 234, 227, 229, 224, 229,...\n",
      "2       [[231, 231, 231, 239, 240, 234, 233, 231, 236,...\n",
      "3       [[232, 232, 232, 238, 239, 233, 233, 230, 234,...\n",
      "4       [[230, 230, 230, 235, 239, 234, 232, 228, 234,...\n",
      "                              ...                        \n",
      "1061    [[251, 253, 252, 253, 252, 253, 253, 252, 253,...\n",
      "1062    [[230, 230, 232, 236, 237, 233, 234, 226, 233,...\n",
      "1063    [[226, 228, 229, 234, 236, 229, 231, 225, 233,...\n",
      "1064    [[231, 232, 232, 237, 240, 234, 234, 230, 235,...\n",
      "1065    [[229, 229, 230, 235, 238, 232, 232, 228, 235,...\n",
      "Name: reshaped_embeddings, Length: 1066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(gpt['reshaped_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(gpt['reshaped_embeddings'][10], cmap='gray')  # Assuming grayscale image\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(gpt['reshaped_embeddings'])):\n",
    "    plt.imshow(gpt['reshaped_embeddings'][i], cmap='gray')  # Assuming grayscale image\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/output/GPT/'+str(i)+'.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "human['embeddings'] = human['Generation'].apply(generate_bert_embeddings)\n",
    "human['normalized_embeddings'] = human['embeddings'].apply(min_max_normalize)\n",
    "human['reshaped_embeddings'] = human['normalized_embeddings'].apply(reshape_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(human['reshaped_embeddings'])):\n",
    "    plt.imshow(human['reshaped_embeddings'][i], cmap='gray')  # Assuming grayscale image\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.savefig('/home/csgrad/sunilruf/detect_llm/sunil_code/output/Human/'+str(i)+'.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
